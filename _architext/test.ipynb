{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe37960",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930c63df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"architext/gptj-162M\", use_auth_token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"architext/gptj-162M\", use_auth_token=token).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd5add12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_TOKEN=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\n"
     ]
    }
   ],
   "source": [
    "# Fill in your token\n",
    "%set_env HF_TOKEN="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53fa9670",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "seed_prompts = np.loadtxt('prompts.txt', dtype=str, delimiter='\\n')\n",
    "seed_prompts = [prompt.rstrip() for prompt in seed_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9949cc51",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(**tokenizer('[prompt] '+ seed_prompts[0] +' [layout]', return_tensors='pt').to(device), do_sample=True, num_beams=10, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ee00d54",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[prompt] a house with five rooms [layout] bedroom1: (113,135)(55,135)(55,91)(113,91), bathroom1: (157,165)(128,165)(128,135)(157,135), bedroom2: (201,135)(172,135)(172,91)(201,91), living_room: (172,135)(113,135)(113,77)(172,77), kitchen: (128,165)(84,165)(84,135)(128,135), bathroom2: (84,179)(55,179)(55,135)(84,135), bedroom3: (201,165)(157,165)(157,135)(201,135) <|endoftext|>']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7833ac5a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MAPElites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f644028",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## (Not production codes!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d709e0b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Union, TypeVar, Generic\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "\n",
    "Phenotype = Optional[np.ndarray]\n",
    "Mapindex = Optional[tuple]\n",
    "\n",
    "# This Genotype class is implemented in Herbie's cleanup branch. Need to delete if you merge.\n",
    "class Genotype(ABC):\n",
    "    def __str__(self) -> str:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "GenoType = TypeVar('GenoType', bound=Genotype)\n",
    "        \n",
    "class MAPElites:\n",
    "    def __init__(self, env, n_bins: int, history_length: int):\n",
    "        self.env = env\n",
    "        self.n_bins = n_bins\n",
    "        self.history_length = history_length\n",
    "        self.history = []\n",
    "\n",
    "        # discretization of behaviour space\n",
    "        self.bins = np.linspace(*env.behaviour_space, n_bins + 1)[1:-1].T\n",
    "        # perfomance of niches\n",
    "        self.fitnesses = np.full([n_bins] * env.behaviour_ndim, -np.inf)\n",
    "        # niches' sources\n",
    "        self.genomes = np.zeros(self.fitnesses.shape, dtype=object)\n",
    "        # index over explored niches to select from\n",
    "        self.nonzero = np.full(self.fitnesses.shape, False)\n",
    "\n",
    "        # bad mutations that ended up with invalid output.\n",
    "        self.recycled = [None] * 1000\n",
    "        self.recycled_count = 0\n",
    "\n",
    "        print(f\"MAP of size: {self.fitnesses.shape} = {self.fitnesses.size}\")\n",
    "\n",
    "    def to_mapindex(self, b: Phenotype) -> Mapindex:\n",
    "        return None if b is None else tuple(np.digitize(x, bins) for x, bins in zip(b, self.bins))\n",
    "\n",
    "    def random_selection(self) -> Mapindex:\n",
    "        ix = np.random.choice(np.flatnonzero(self.nonzero))\n",
    "        return np.unravel_index(ix, self.nonzero.shape)\n",
    "\n",
    "    def search(self, initsteps: int, totalsteps: int, atol=1, batch_size=32):\n",
    "        tbar = trange(int(totalsteps))\n",
    "        max_fitness = -np.inf\n",
    "        max_genome = None\n",
    "\n",
    "        config = {'batch_size': batch_size}\n",
    "\n",
    "        for n_steps in tbar:\n",
    "            self.history.append(self.genomes)\n",
    "            \n",
    "            if n_steps < initsteps:\n",
    "                # Initialise by generating initsteps random solutions.\n",
    "                #comment: here we can sample 1 layout out of each prompt, to initiate the map\n",
    "                x = self.env.random(**config)\n",
    "            else:\n",
    "                # Randomly select an elite from the map\n",
    "                map_ix = self.random_selection()\n",
    "                x = self.genomes[map_ix]\n",
    "                # Mutate the elite\n",
    "                x = self.env.mutate(x, **config)\n",
    "\n",
    "            # Now that `x` is a list, we put them into the behaviour space one-by-one.\n",
    "            for individual in x:\n",
    "                map_ix = self.to_mapindex(self.env.to_behaviour_space(individual))\n",
    "                \n",
    "                # if the return is None, the individual is invalid and is thrown into the recycle bin.\n",
    "                # comment: we should keep infeasible designs here if we can; eventually we'd need a metric of how far they are from a valid design\n",
    "                if map_ix is None:\n",
    "                    self.recycled[self.recycled_count % len(self.recycled)] = individual\n",
    "                    self.recycled_count += 1\n",
    "                    continue\n",
    "                \n",
    "                self.nonzero[map_ix] = True\n",
    "\n",
    "                f = self.env.fitness(individual)\n",
    "                # If new fitness greater than old fitness in niche, replace.\n",
    "\n",
    "                if f > self.fitnesses[map_ix]:\n",
    "                    self.fitnesses[map_ix] = f\n",
    "                    self.genomes[map_ix] = individual\n",
    "                # If new fitness is the highest so far, update the tracker.\n",
    "                if f > max_fitness:\n",
    "                    max_fitness = f\n",
    "                    max_genome = individual\n",
    "\n",
    "                    tbar.set_description(f'{max_fitness=:.4f} of \"{str(max_genome)}\"')\n",
    "                # If best fitness is within atol of the maximum possible fitness, stop.\n",
    "                if np.isclose(max_fitness, self.env.max_fitness, atol=atol):\n",
    "                    break\n",
    "\n",
    "        return str(self.genomes[np.unravel_index(self.fitnesses.argmax(), self.fitnesses.shape)])\n",
    "\n",
    "    def plot(self):\n",
    "        import matplotlib\n",
    "        from matplotlib import pyplot\n",
    "\n",
    "        matplotlib.rcParams['font.family'] = 'Futura'\n",
    "        matplotlib.rcParams['figure.dpi'] = 100\n",
    "        matplotlib.style.use('ggplot')\n",
    "\n",
    "        ix = tuple(np.zeros(self.fitnesses.ndim - 2, int))\n",
    "        print(ix)\n",
    "        map2d = self.fitnesses[ix]\n",
    "        print(f'{map2d.shape=}')\n",
    "\n",
    "        pyplot.pcolor(map2d, cmap='inferno')\n",
    "        pyplot.show()\n",
    "        \n",
    "class BaseEnvironment(ABC, Generic[GenoType]):\n",
    "    def __init__(self) -> None:\n",
    "        self.genotype_space: np.ndarray\n",
    "\n",
    "    @abstractmethod\n",
    "    def random(self, n_seed, **kwarg) -> list[GenoType]:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abstractmethod\n",
    "    def mutate(self, x: GenoType, **kwarg) -> list[GenoType]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def fitness(self, x: GenoType) -> float:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def to_behaviour_space(self, x: GenoType) -> Phenotype:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def max_fitness(self) -> int:\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    # [starts, endings) of search intervals\n",
    "    def behaviour_space(self) -> np.ndarray:\n",
    "        return self.genotype_space\n",
    "\n",
    "    @property\n",
    "    def behaviour_ndim(self) -> int:\n",
    "        return self.behaviour_space.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7990fd70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## new codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6b4ffbf2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: random seed and config are not really used in the Architext class. Need to also put them into the right\n",
    "# places in production code.\n",
    "\n",
    "import os\n",
    "import random\n",
    "from abc import ABC\n",
    "from math import log, e\n",
    "import re\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry import shape\n",
    "from shapely.affinity import scale\n",
    "from shapely.ops import unary_union\n",
    "import networkx as nx\n",
    "\n",
    "def calc_entropy(labels, base=None):\n",
    "  \"\"\" Computes entropy of label distribution. \"\"\"\n",
    "  n_labels = len(labels)\n",
    "  if n_labels <= 1:\n",
    "    return 0\n",
    "  value,counts = np.unique(labels, return_counts=True)\n",
    "  probs = counts / n_labels\n",
    "  n_classes = np.count_nonzero(probs)\n",
    "  if n_classes <= 1:\n",
    "    return 0\n",
    "  ent = 0.\n",
    "  # Compute entropy\n",
    "  base = e if base is None else base\n",
    "  for i in probs:\n",
    "    ent -= i * log(i, base)\n",
    "  return ent\n",
    "\n",
    "def get_value(dictionary, val):\n",
    "    for key, value in dictionary.items():\n",
    "        if val == key:\n",
    "            return value\n",
    " \n",
    "    return \"value doesn't exist\"\n",
    "\n",
    "def get_key(dictionary, val):\n",
    "    for key, value in dictionary.items():\n",
    "        if val == value:\n",
    "            return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "def find_intersections(seed_polygon, target_polygons):\n",
    "    \"\"\"\n",
    "        A function that finds intersections between a seed polygon and a list of candidate polygons.\n",
    "\n",
    "    Args:\n",
    "        seed_polygon (shapely polygon): A shapely polygon.\n",
    "        target_polygons (list): A list of shapely polygons.\n",
    "\n",
    "    Returns:\n",
    "        array: The intersection matrix between the seed polygon and all individual target polygons.\n",
    "    \"\"\"\n",
    "    intersect_booleans = []\n",
    "    for _, poly in enumerate(target_polygons):\n",
    "        try:\n",
    "            intersect_booleans.append(seed_polygon.intersects(poly))\n",
    "        except:\n",
    "            intersect_booleans.append(True)\n",
    "    return intersect_booleans\n",
    "\n",
    "def find_distance(seed_graph, target_graphs):\n",
    "    \"\"\"\n",
    "        A function that finds intersections between a seed polygon and a list of candidate polygons.\n",
    "\n",
    "    Args:\n",
    "        seed_polygon (shapely polygon): A shapely polygon.\n",
    "        target_polygons (list): A list of shapely polygons.\n",
    "\n",
    "    Returns:\n",
    "        array: The intersection matrix between the seed polygon and all individual target polygons.\n",
    "    \"\"\"\n",
    "    distances = [nx.graph_edit_distance(seed_graph, graph) for graph in target_graphs]\n",
    "    return distances\n",
    "\n",
    "housegan_labels = {\"living_room\": 1, \"kitchen\": 2, \"bedroom\": 3, \"bathroom\": 4, \"missing\": 5, \"closet\": 6, \n",
    "                         \"balcony\": 7, \"corridor\": 8, \"dining_room\": 9, \"laundry_room\": 10}\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "\n",
    "class LocalGenerator:\n",
    "    \"\"\"\n",
    "    An ad hoc implementation of generating hf outputs on the local machine. Just to make things run temporarily and \n",
    "    may not be final in the repo.\n",
    "    \"\"\"\n",
    "    def __init__(self, token, model_str='architext/gptj-162M'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            token: hf token.\n",
    "            model_str: (Optional) hf model string.\n",
    "        \"\"\"\n",
    "        self.token = token\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_str, use_auth_token=self.token)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_str, use_auth_token=self.token)\n",
    "        \n",
    "    def __call__(self, prompt, **kwargs):\n",
    "        output = self.model.generate(**self.tokenizer(prompt, return_tensors='pt'), **kwargs)\n",
    "        return self.tokenizer.batch_decode(output)\n",
    "        \n",
    "\n",
    "class ArchitextGenotype(Genotype):\n",
    "    def __init__(self, code: str, layout: Optional[str]):\n",
    "        self.code = code\n",
    "        self.layout = layout\n",
    "        self.valid = self.validate()\n",
    "    \n",
    "    def get_clean_layout(self) -> str:\n",
    "        if(len(self.layout.split('[layout]')) > 1):\n",
    "            clean_layout = self.layout.split('[layout]')[1].split('[User prompt]')[0].split(', ')\n",
    "        else:\n",
    "            clean_layout = self.layout.split('[Layout]')[1].split('[User prompt]')[0].split(', ')\n",
    "        return clean_layout\n",
    "\n",
    "    def get_spaces(self) -> list:\n",
    "        clean_layout = self.get_clean_layout()\n",
    "        spaces = [re.sub(r'\\d+', '', txt.split(':')[0]).lstrip() for txt in clean_layout]\n",
    "        return spaces\n",
    "\n",
    "    def get_space_ids(self) -> list:\n",
    "        spaces = self.get_spaces()\n",
    "        space_ids = [get_value(housegan_labels, space) for space in spaces]\n",
    "        return space_ids\n",
    "\n",
    "    def get_coordinates(self) -> list:\n",
    "        clean_layout = self.get_clean_layout()\n",
    "        coordinates = [txt.split(':')[1] for txt in self.layout if len(txt.split(':')) > 1]\n",
    "        coordinates = [re.findall(regex, coord) for coord in coordinates]\n",
    "        coordinates = [x for x in coordinates if x != []]\n",
    "        return coordinates\n",
    "\n",
    "    def get_polygons(self) -> list:\n",
    "        coordinates = self.get_coordinates()\n",
    "        rectangles = []\n",
    "        polygons = []\n",
    "        for coord in coordinates:\n",
    "            rectangles.append([point.split(',') for point in coord])\n",
    "        for rec in rectangles:\n",
    "            rec = [x for x in rec if x != ['']]\n",
    "            rec = [x for x in rec if '' not in x] \n",
    "            polygons.append(Polygon(np.array(rec, dtype=int)))\n",
    "\n",
    "        return polygons\n",
    "\n",
    "    def gfa(self) -> str:\n",
    "        polygons = self.get_polygons\n",
    "        gfa = [poly.area() for poly in polygons]\n",
    "        return gfa\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.layout if self.valid else \"\"\n",
    "\n",
    "    def validate(self) -> bool:\n",
    "        return isinstance(self.layout, str)\n",
    "\n",
    "    def adjacency_matrix(self):\n",
    "        scaled_polygons = []\n",
    "        for polygon in self.get_polygons():\n",
    "            scaled_polygons.append(scale(polygon, 1.15, 1.15, origin=polygon.centroid))\n",
    "        intersection_matrix = np.zeros((len(scaled_polygons), len(scaled_polygons)))\n",
    "        for k, p in enumerate(scaled_polygons):\n",
    "            intersection_matrix[:, k] = find_intersections(p, scaled_polygons)\n",
    "        return intersection_matrix\n",
    "\n",
    "    def create_node_dict(self):\n",
    "        space_ids = self.get_space_ids()\n",
    "        values = [get_key(housegan_labels, id_) for id_ in space_ids]\n",
    "        keys = np.arange(len(space_ids))\n",
    "        return dict(zip(keys, values))\n",
    "\n",
    "    def get_labelled_graph(self) -> list:\n",
    "        adj_matrix = self.adjacency_matrix()\n",
    "        labels = self.create_node_dict()\n",
    "        graph = nx.from_numpy_matrix(adj_matrix)\n",
    "        nx.relabel.relabel_nodes(graph, labels, copy=False)\n",
    "        return graph\n",
    "\n",
    "    def hlff(self) -> float:\n",
    "        #Quality - hlff\n",
    "        joined = unary_union(self.get_polygons) # need to add this property to individual\n",
    "        surface_area = joined.length * self.height #\n",
    "        floor_area = joined.area()\n",
    "        hlff = (2*floor_area + surface_area) / floor_area\n",
    "        return hlff\n",
    "\n",
    "    def gfa_entropy(self) -> float:\n",
    "        room_gfa = [rm.area() for rm in self.get_polygons]\n",
    "        gfa_entropy = calc_entropy(room_gfa)\n",
    "        return gfa_entropy\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "This was my individual class in my arch-elites experiment. I think it might be nice to add some of these properties to the designs, especially geometrical properties.\n",
    "We can then retrieve these quite easily during the MAP-Elites run.\n",
    "class Individual:\n",
    "\tdef __init__(self, collection, id_, cmap, size):\n",
    "\t\t\"\"\n",
    "\t\tA class to create an individual, along with its properties, out of the provided collection.\n",
    "\n",
    "\t\t:param id_: The indice of the individual in the collection\n",
    "\t\t:param cmap: The color gradient map that represents heights into colors, as it was extracted from\n",
    "\t\tthe grasshopper model.\n",
    "\t\t:param size: The extend of the bounding box of an individual, in meters. Used to generate appropriate\n",
    "\t\timage outputs.\n",
    "\t\t\"\"\n",
    "\n",
    "\t\tself.parent_ids = None\n",
    "\t\tself.grid_position = None\n",
    "\n",
    "\t\t# generate phenotype\n",
    "\t\tself.polygons = geom.create_shapely_polygons(self.points, self.splits)\n",
    "\n",
    "\t\t# calcualte features and descriptors\n",
    "\t\tself.footprints = np.array([polygon.area for polygon in self.polygons])\n",
    "\t\tself.feature_names = ['FSI', 'GSI', 'OSR', 'Mean_height', 'Tare']\n",
    "\t\tself.features = dict(zip(self.feature_names, geom.get_features(self.footprints, self.heights)))\n",
    "\t\tself.centroids = np.array(geom.centroids(self.polygons))\n",
    "\t\tself.std = util.calc_std(self.heights)\n",
    "\t\tself.dangerous = None\n",
    "\t\tself.sitting = None\n",
    "\n",
    "\tdef draw_image(self):\n",
    "\n",
    "\t\t_, image = geom.draw_polygons(self.polygons, self.colors, self.size)\n",
    "\n",
    "\t\treturn image\n",
    "\n",
    "\tdef save_to_disk(self, fname):\n",
    "\n",
    "\t\tdata = {'polygons': self.polygons, 'heights': self.heights,\n",
    "\t\t\t\t'colors': self.colors, 'footprints:': self.footprints,\n",
    "\t\t\t\t'features': self.features, 'parent_id': self.parent_ids,\n",
    "\t\t\t\t'grid_position': self.grid_position}\n",
    "\n",
    "\t\twith open(fname, 'wb') as file:\n",
    "\t\t\tpickle.dump(data, file)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Architext(BaseEnvironment):\n",
    "    \"\"\"\n",
    "    This will try to mutate layouts using architext-FIM models. \n",
    "    \n",
    "    The Heat Loss Form Factor will be used as the quality metric, defined as: \n",
    "    heat loss form factor = heat loss area / treated floor area, assuming that all area is treated. \n",
    "    Numerically, this is calculated as: hllff = sum(surface_area) / floor_area\n",
    "\n",
    "    The behavioral descriptors will be layout typology (measured by number of bedrooms and bathrooms) and the entropy\n",
    "    of the floor area distribution across different spaces in the layout.\n",
    "    \"\"\"\n",
    "    # Record different definitions of behaviour spaces in a dict. Feel free to add.\n",
    "    behaviour_mode_spec = {'hlff_and_fae':\n",
    "                               {'genotype_ndim': 2,\n",
    "                                'genotype_space': np.array([[0, 3.25], [0, 1.25]]).T\n",
    "                               }\n",
    "                          }\n",
    "    model_param = {'do_sample': True,\n",
    "                   'num_beams': 5, \n",
    "                   'max_length': 300}\n",
    "\n",
    "    def __init__(self, seed: str, config: Union[str, dict, DictConfig], target_layout: str, prompts: list, n_mutations: int, height: float,\n",
    "                 inference_server=None, behaviour_mode='hlff_and_fae', model_param=model_param, np_rng):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            seed: the seed layouts.\n",
    "            config: the config file or dict.\n",
    "            target_layout: the target layout.\n",
    "            n_mutations: the number of mutations per individual selected from the map\n",
    "            prompts: list of different prompts that can be attached to selected layouts.\n",
    "            inference_server: (Optional) the address of the inference server: 'domain:port'. If None, load model locally.\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        self.n_mutations = n_mutations\n",
    "        self.height = height\n",
    "        self.np_rng = np.random.RandomState(seed=np.randint(1, 1e10))\n",
    "\n",
    "        if isinstance(config, str):\n",
    "            self.config = OmegaConf.load(config)\n",
    "        elif isinstance(config, (dict, DictConfig)):\n",
    "            self.config = DictConfig(config)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "        self.target_layout = target_layout\n",
    "        self.prompts = prompts\n",
    "        self.model_param = model_param\n",
    "\n",
    "        # Use RNG to rotate random seeds during inference.\n",
    "        self.rng = np.random.default_rng(seed=self.config.seed)\n",
    "\n",
    "        self.behaviour_mode = behaviour_mode\n",
    "        self.genotype_ndim = self.behaviour_mode_spec[self.behaviour_mode]['genotype_ndim']\n",
    "        self.genotype_space = self.behaviour_mode_spec[self.behaviour_mode]['genotype_space']\n",
    "        \n",
    "        #map_dim = 12 x 10 = 120\n",
    "\n",
    "        self.inference_server = inference_server\n",
    "        self.local_generator = LocalGenerator(os.environ['HF_TOKEN']) if self.inference_server is None else None\n",
    "\n",
    "    def random(self, **kwargs) -> List[ArchitextGenotype]:\n",
    "        \"\"\"\n",
    "        Sample layouts from the model by randomly selecting prompts.\n",
    "        Returns:\n",
    "            the generated layout in a string representation.\n",
    "        \"\"\"\n",
    "        return list(map(lambda x: ArchitextGenotype(code='', layout=x),\n",
    "                        self._get_layout(self.seed + random.choice(self.prompts), **self.model_param, **kwargs)))\n",
    "\n",
    "\n",
    "    def mutate(self, x: Genotype, **kwargs) -> List[ArchitextGenotype]:\n",
    "        \"\"\"\n",
    "        Take in a sample (np array w/ size (0,chunklength)) and perform a FIM transformation\n",
    "        on spaces in the layout *only* \n",
    "        example (ignore newlines): \n",
    "        --------------------------------\n",
    "        [prompt] a bedroom is adjacent to the kitchen \n",
    "        [layout] bedroom1: (194,91)(135,91)(135,47)(194,47), \n",
    "        living_room: (121,194)(47,194)(47,91)(106,91)(106,106)(121,106), \n",
    "        bathroom1: (179,121)(135,121)(135,91)(179,91), \n",
    "        bedroom2: (209,165)(135,165)(135,121)(209,121), \n",
    "        bathroom2: (165,209)(135,209)(135,165)(165,165), \n",
    "        bedroom3: (121,238)(47,238)(47,194)(121,194), \n",
    "        kitchen: (135,77)(106,77)(106,18)(135,18), \n",
    "        corridor: (121,209)(121,106)(106,106)(106,77)(135,77)(135,209) <|endoftext|>\n",
    "        --------------------------------\n",
    "        The transform will mask one or more spaces from the layout (instead of a random span). \n",
    "        The model can then be tasked with predicting the masked spaces.\n",
    "        --------------------------------\n",
    "        <prefix token>\n",
    "        [prompt] a bedroom is adjacent to the kitchen \n",
    "        [layout] bedroom1: (194,91)(135,91)(135,47)(194,47), \n",
    "        living_room: (121,194)(47,194)(47,91)(106,91)(106,106)(121,106), \n",
    "        <suffix token>\n",
    "        bedroom2: (209,165)(135,165)(135,121)(209,121), \n",
    "        bathroom2: (165,209)(135,209)(135,165)(165,165), \n",
    "        bedroom3: (121,238)(47,238)(47,194)(121,194), \n",
    "        kitchen: (135,77)(106,77)(106,18)(135,18), \n",
    "        corridor: (121,209)(121,106)(106,106)(106,77)(135,77)(135,209) \n",
    "        <mask token>\n",
    "        --------------------------------\n",
    "        \"\"\"\n",
    "\n",
    "        #this btw requires the NeoX tokenizer: tokenizer = neox_args.tokenizer and NeoX FIM models\n",
    "        suffix_tok_id, prefix_tok_id, middle_tok_id = self.tokenizer.vocab_size - 1, self.tokenizer.vocab_size, self.tokenizer.vocab_size + 1\n",
    "        \n",
    "        #get full layout\n",
    "        contents = self.tokenizer.detokenize(x)\n",
    "        # parse spaces from the layout\n",
    "        prompt, layout = contents.split(\"[layout]\")\n",
    "        spaces = layout.split(\", \")\n",
    "        spaces = [s.strip() for s in spaces]\n",
    "        mutated_layouts = []\n",
    "        for i in range(0, self.n_mutations):\n",
    "            try:\n",
    "                # sample a number of spaces to mask, \n",
    "                # mask at least one, keep at least one ?\n",
    "                num_spaces = self.np_rng.randint(1, len(spaces)-1)\n",
    "                # select what contiguous spaces to mask\n",
    "                start_idx = self.np_rng.randint(0, len(spaces)-num_spaces)\n",
    "                end_idx = start_idx + num_spaces\n",
    "            except ValueError as e:\n",
    "                # should probably pass this result to failed mutations, or maybe throw it away and retry idk\n",
    "                print(len(contents), contents)\n",
    "                print(e)\n",
    "                raise e\n",
    "\n",
    "            prefix = prompt + \"[layout] \" + \", \".join(spaces[:start_idx])\n",
    "            #middle = \", \".join(spaces[start_idx:end_idx])\n",
    "            suffix = \", \".join(spaces[end_idx:]) + \" \"\n",
    "\n",
    "            suffix = np.array([suffix_tok_id, *tokenizer.tokenize(suffix)])\n",
    "            prefix = np.array([prefix_tok_id, *tokenizer.tokenize(prefix)])\n",
    "            #middle = np.array([middle_tok_id, *tokenizer.tokenize(middle)])\n",
    "\n",
    "            new_layout = np.concatenate([\n",
    "                prefix,\n",
    "                suffix,\n",
    "                middle_tok_id,\n",
    "            ])\n",
    "\n",
    "            mutated_layouts.append(new_layout)\n",
    "\n",
    "        return [self.local_generator(layout, batch_size=1, **kwargs) for layout in mutated_layouts]\n",
    "\n",
    "    def fitness(self, x: ArchitextGenotype) -> float:\n",
    "        hlff = x.hlff()\n",
    "        return hlff\n",
    "\n",
    "    def to_behaviour_space(self, x: ArchitextGenotype) -> Phenotype:\n",
    "        # TODO: Implement this\n",
    "        return np.random.random((self.genotype_ndim,))\n",
    "\n",
    "    def to_string(self, x: ArchitextGenotype) -> str:\n",
    "        return str(x)\n",
    "\n",
    "    def _get_layout(self, full_prompt, batch_size=1, **kwargs) -> Genotype:\n",
    "        # TODO: batch size > 1 need to be implemented\n",
    "        if self.inference_server is None:\n",
    "            return [self.local_generator(full_prompt, batch_size=batch_size, **kwargs)]\n",
    "        else:\n",
    "            # TODO: Implement this.\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    @staticmethod\n",
    "    def _has_valid_output(x: ArchitextGenotype) -> bool:\n",
    "        return x.valid\n",
    "\n",
    "    def _update_seed(self):\n",
    "        \"\"\"\n",
    "        Update the random seed in `self.config.seed` using `self.rng`.\n",
    "        \"\"\"\n",
    "        self.config.seed = int(self.rng.integers(0, 1e8))\n",
    "\n",
    "    @property\n",
    "    def max_fitness(self):\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    # [starts, endings) of search intervals\n",
    "    def behaviour_space(self):\n",
    "        return self.genotype_space\n",
    "\n",
    "    @property\n",
    "    def behaviour_ndim(self):\n",
    "        return self.behaviour_space.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66b21e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a2a58b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP of size: (12, 12) = 144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "max_fitness=0.5117 of \"\":  50%|█████     | 1/2 [00:06<00:06,  6.75s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "max_fitness=0.5117 of \"\": 100%|██████████| 2/2 [00:13<00:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best image \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed = \"\"\n",
    "target = \"bedroom1: (194,106)(165,106)(165,47)(194,47), living_room: (179,223)(106,223)(106,121)(165,121)(165,135)(179,135), bathroom1: (165,106)(135,106)(135,77)(165,77), bedroom2: (135,106)(91,106)(91,33)(135,33), bathroom2: (106,165)(77,165)(77,135)(106,135), bedroom3: (91,106)(77,106)(77,121)(47,121)(47,62)(91,62), kitchen: (209,194)(179,194)(179,135)(194,135)(194,121)(209,121), corridor: (194,135)(165,135)(165,121)(106,121)(106,135)(77,135)(77,106)(194,106) <|endoftext|>\"\n",
    "prompts = [\"[prompt] a house with seven rooms and a corridor [layout]\",\n",
    "          \"[prompt] a bedroom is located in the east side of the house [layout]\",\n",
    "          \"[prompt] a house with two bedrooms and one bathroom [layout]\"]\n",
    "\n",
    "config = {'seed': 42, }\n",
    "env = Architext(seed, config, target_layout=target, prompts=prompts)\n",
    "elites = MAPElites(env, n_bins=12, history_length=10)\n",
    "print(\"Best image\", elites.search(initsteps=2, totalsteps=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ff20d971",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[prompt] a bedroom is located in the east side of the house [layout] bedroom1: (91,135)(33,135)(33,106)(91,106), living_room: (135,209)(33,209)(33,135)(135,135), bathroom1: (135,121)(106,121)(106,77)(135,77), bedroom2: (209,179)(135,179)(135,135)(194,135)(194,121)(209,121), bathroom2: (223,121)(194,121)(194,106)(179,106)(179,91)(223,91), bedroom3: (179,106)(135,106)(135,47']\n",
      "['[prompt] a house with two bedrooms and one bathroom [layout] bedroom1: (165,223)(135,223)(135,165)(165,165), living_room: (135,150)(47,150)(47,77)(135,77), bathroom1: (179,165)(150,165)(150,121)(179,121), bedroom2: (209,121)(150,121)(150,62)(209,62), bathroom2: (165,62)(121,62)(121,33)(165,33), bedroom3: (121,62)(47,62)(47,33)(121,33), kitchen: (135,209)(91,209)(91,150)(135,150),']\n"
     ]
    }
   ],
   "source": [
    "for a in np.ravel(elites.history[-1]):\n",
    "    if isinstance(a, Genotype):\n",
    "        print(a.layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "26d5f38e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elites.history[-1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a0b6f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Architext's evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a77328",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "{'semantic_accuracy': [True, True, True], 'reward': [[0], [-1], [0]]}\n"
     ]
    }
   ],
   "source": [
    "from design_eval import eval_function\n",
    "from utils import *\n",
    "\n",
    "test_data = {\n",
    "    'samples': ['[prompt] a house with seven rooms and a corridor [layout] bedroom1: (194,106)(165,106)(165,47)(194,47), living_room: (179,223)(106,223)(106,121)(165,121)(165,135)(179,135), bathroom1: (165,106)(135,106)(135,77)(165,77), bedroom2: (135,106)(91,106)(91,33)(135,33), bathroom2: (106,165)(77,165)(77,135)(106,135), bedroom3: (91,106)(77,106)(77,121)(47,121)(47,62)(91,62), kitchen: (209,194)(179,194)(179,135)(194,135)(194,121)(209,121), corridor: (194,135)(165,135)(165,121)(106,121)(106,135)(77,135)(77,106)(194,106) <|endoftext|>',\n",
    "                '[prompt] a bedroom is located in the east side of the house [layout] bathroom1: (135,99)(91,99)(91,69)(135,69), bedroom1: (121,69)(77,69)(77,25)(121,25), living_room: (179,157)(135,157)(135,69)(179,69), kitchen: (135,157)(91,157)(91,99)(135,99), bedroom2: (179,187)(121,187)(121,157)(179,157), bathroom2: (121,187)(91,187)(91,157)(121,157), bedroom3: (165,231)(106,231)(106,187)(165,187), bedroom4: (179,69)(121,69)(121,25)(179,25) <|endoftext|>',\n",
    "                '[prompt] a house with two bedrooms and one bathroom [layout] bedroom1: (135,135)(91,135)(91,77)(135,77), living_room: (194,135)(135,135)(135,62)(194,62), kitchen: (194,194)(165,194)(165,135)(194,135), bedroom2: (150,165)(106,165)(106,135)(150,135), bathroom: (106,165)(62,165)(62,135)(106,135) <|endoftext|>'],\n",
    "    'prompts': ['a house with seven rooms and a corridor', \n",
    "                'a bedroom is located in the east side of the house',\n",
    "                'a house with two bedrooms and one bathroom'],\n",
    "    'prompt_types': ['total_number_prompt', 'location_prompt', 'ind_number_prompt']\n",
    "    }\n",
    "\n",
    "\n",
    "semantic_accuracy = []\n",
    "reward = []\n",
    "samples, prompts, prompt_types = test_data['samples'], test_data['prompts'], test_data['prompt_types']\n",
    "results = eval_function(samples, prompts, prompt_types)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2422dbf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.choice([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46428bbe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('ldm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e22725111cb5104d6908b191ea48e4f58131f193789607affc0d56389e7c3fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}